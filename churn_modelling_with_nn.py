# -*- coding: utf-8 -*-
"""Churn_Modelling with NN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yBS_SP0w_rkYH0_5HA6LHRuiH2rKZRps
"""

from tensorflow.keras.layers import Input,Dense
from tensorflow.keras.models import Model
from google.colab import files
import pandas as pd
import numpy as np
uploaded = files.upload()

data=pd.read_csv("Churn_Modelling.csv")

y=data.iloc[:,-1].values
X=data.iloc[:,3:-1].values

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
X[:,1]=le.fit_transform(X[:,1])

le2=LabelEncoder()
X[:,2]=le2.fit_transform(X[:,2])

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
ct = ColumnTransformer([("Geography", OneHotEncoder(), [1])], remainder = 'passthrough')

X=ct.fit_transform(X)
X=X[:,1:]

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=0)

from sklearn.preprocessing import  StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)




inputs=Input(shape=(11,))

output_1=Dense(6,activation="relu")(inputs)
output_2=Dense(6,activation="relu")(output_1)
predictions=Dense(1,activation="sigmoid")(output_2)


model=Model(inputs=inputs,outputs=predictions)
model.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

model.fit(X_train,y_train,epochs=10)


pred=model.evaluate(X_test,y_test,batch_size=32)

